[
  { "metric_name": "ai_request_total", "chart_type": "timeseries", "prom_type": "Counter" },
  { "metric_name": "ai_request_latency_seconds", "chart_type": "bargauge", "prom_type": "Histogram" },
  { "metric_name": "model_inferences_total", "chart_type": "timeseries", "prom_type": "Counter" },
  { "metric_name": "model_inference_errors_total", "chart_type": "timeseries", "prom_type": "Counter" },
  { "metric_name": "model_response_time_seconds", "chart_type": "bargauge", "prom_type": "Histogram" },
  { "metric_name": "model_batch_size", "chart_type": "timeseries", "prom_type": "Histogram" },
  { "metric_name": "model_input_data_size_bytes", "chart_type": "timeseries", "prom_type": "Histogram" },
  { "metric_name": "model_output_data_size_bytes", "chart_type": "timeseries", "prom_type": "Histogram" },
  { "metric_name": "model_input_tokens_total", "chart_type": "timeseries", "prom_type": "Histogram" },
  { "metric_name": "model_output_tokens_total", "chart_type": "timeseries", "prom_type": "Histogram" },
  { "metric_name": "ai_model_accuracy", "chart_type": "gauge", "prom_type": "Gauge" },
  { "metric_name": "ai_model_loss", "chart_type": "gauge", "prom_type": "Gauge" },
  { "metric_name": "ai_memory_usage_bytes", "chart_type": "gauge", "prom_type": "Gauge" },
  { "metric_name": "ai_cpu_usage_percent", "chart_type": "gauge", "prom_type": "Gauge" },
  { "metric_name": "ai_gpu_memory_usage_bytes", "chart_type": "gauge", "prom_type": "Gauge" },
  { "metric_name": "ai_gpu_utilization_percent", "chart_type": "gauge", "prom_type": "Gauge" }
]
